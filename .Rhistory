install.packages("sqldf")
library("sqldf", lib.loc="C:/Users/Jeffrey/Documents/R/win-library/3.1")
?read2.csv.sql()
?read.csv2.sql()
myfile<-"./household_power_consumption.txt"
mySQL<-"SELECT * from file WHERE Date='02/02/2007'or Date='01/02/2007' "
smallData<-read.csv2.sql(myfile,mySQL,header=True)
smallData<-read.csv2.sql(myfile,mySQL)
mySQL<-"SELECT * from file WHERE Date='2/2/2007'or Date='1/2/2007' "
smallData<-read.csv2.sql(myfile,mySQL)
install.packages("plyr")
install.packages("ggplot2")
source('~/EDA_Project2/WIP.R')
levels(SCC$EI.Sector)
source('~/EDA_Project2/WIP.R')
source('~/EDA_Project2/plot1.R')
source('~/EDA_Project2/plot2.R')
source('~/EDA_Project2/plot2.R')
source('~/EDA_Project2/plot3.R')
totalByTypeYear
qplot(year,total,data=totalByTypeYear,facets=.~type)
source('~/EDA_Project2/plot4.R')
source('~/EDA_Project2/plot4.R')
source('~/EDA_Project2/plot5.R')
source('~/EDA_Project2/plot6.R')
qplot(year,total,data=twoCitiesByYear,facets=.~fips)
?download.file()
q4q1data<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile="q4q1Data.csv")
quiz4q1Data<-read.csv("./q4q1Data.csv")
?strsplit()
colnames(quiz4q1Data)
q1Vector<-strsplit(colnames(quiz4q1Data),"wgtp")
q1Vector[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="q4q2Data.csv")
quiz4q2Data<-read.csv("./q4q2Data.csv")
head(quiz4q2Data)
quiz4q2Data<-read.csv("./q4q2Data.csv")
quiz4q2Data<-read.csv("./q4q2Data.csv")
quiz4q2Data$GDP
quiz4q2Data$GDP<-gsub(quiz4q2Data$GDP,",","")
?gsub()
quiz4q2Data$GDP<-gsub(",","",quiz4q2Data$GDP)
quiz4q2Data$GDP
quiz4q2Data<-read.csv("./q4q2Data.csv")
quiz4q2Data$GDP<-as.character(quiz4q2Data$GDP)
quiz4q2Data$GDP<-gsub(",","",quiz4q2Data$GDP)
quiz4q2Data$GDP<-as.numeric(quiz4q2Data$GDP)
mean(quiz4q2Data$GDP)
quiz4q2Data$Country<-as.character(quiz4q2Data$Country)
grep("^United",quiz4q2Data$Country)
quiz4q2Data$Country
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="q4q4Data.csv")
quiz4q4Data<-read.csv("./q4q4Data.csv")
?merge()
q4Merge<-merge(quiz4q4Data,quiz4q2Data,by.x="CountryCode",by.y="CountryCode")
names(q4Merge)
q4Merge[,10]
?grep()
grep("Fiscal year end",q4Merge[,10],value=TRUE)
q4Intermediate<-grep("Fiscal year end",q4Merge[,10],value=TRUE)
grep("June",q4Intermediate,value=TRUE)
q4Intermediate<-grep("June",q4Merge[,10],value=TRUE)
grep("June",q4Merge[,10],value=TRUE)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
amzn
sampleTimes
?type()
typeof(sampleTimes)
typeof(sampleTimes)
?grep()
grep("2012",sampleTimes,value=TRUE)
all2012<-grep("2012",sampleTimes,value=TRUE)
all2012Days<-format(all2012,"%A %b %d")
dates2012<-as.Date(all2012,"%Y-%m-%d")
days2012<-weekdays(dates2012)
grep("Monday",days2012,value=TRUE)
?rexp()
qpr<-rexp(40.0.2)
qpr<-rexp(40,0.2)
mean(qpr)
qpr<-rexp(40,0.2)
mean(qpr)
mean(rexp(40,0.2))
mean(rexp(40,0.2))
mean(rexp(40,0.2))
mean(rexp(40,0.2))
?for
()
sd(rexp(40,0.2))
()
sd(rexp(40,0.2))
sd(rexp(40,0.2))
sd(rexp(40,0.2))
?rbinom
longdata=numeric(length=1000)
longdata=numeric(length=1500)
for {i in 1:1500} ()
for {i in 1:1500} { longdata[i]=mean(rexp(40,0.2))}
for (i in 1:1500) { longdata[i]=mean(rexp(40,0.2))}
mean(longdata)
sd(longdata)
5/sqrt(1500)
?hist
hist(longdata)
for (i in 1:1500) { longdata[i]=mean(rexp(40,0.2))}
mean(longdata)
sd(longdata)
5/sqrt(40)
hist(longdata)
sd(longdata)/sqrt(40)
longdata>(mean(longdata)+1.96*sd(longdata)/sqrt(40))
count(longdata>(mean(longdata)+1.96*sd(longdata)/sqrt(40)))
ul<-mean(longdata)+1.96*sd(longdata)
ll<-mean(longdata)-1.96*sd(longdata)
mean(ll<longdata & ul>longdata)
hist(longdata)
?hist()
hist(longdata,breaks=21)
abline(v=mean(longdata),col="blue",lwd=2)
abline(v=mean(longdata),col="red",lwd=4)
mean(ll<longdata & ul>longdata)
?array()
source('~/Course5Project1.R')
source('~/Course5Project1.R')
source('~/Course5Project1.R')
norm_comp
source('~/Course5Project1.R')
mean(ll<longdata & ul>longdata)
norm_comp
source('~/Course5Project1.R')
source('~/Course5Project1.R')
source('~/Course5Project1.R')
norm_comp
source('~/Course5Project1.R')
norm_comp
source('~/Project1Part2.R')
data(ToothGrowth)
source('~/Project1Part2.R')
summary(ToothGrowth)
source('~/Project1Part2.R')
data(ToothGrowth)
summary(ToothGrowth)
source('~/.active-rstudio-document')
source('~/Project1Part2.R')
t.test(withOJ$len,withVC$len)
withOJmedium<-subset(ToothGrowth, ToothGrowth$supp=="OJ" & ToothGrowth$dose==1.0)
source('~/Project1Part2.R')
t.test(withOJsmall$len,withOJmedium$len)
t.test(withOJmedium$len,withOJsmall$len)
t.test(withOJlarge$len,withOJmedium$len)
t.test(withVCmedium$len,withVCsmall$len)
t.test(withVClarge$len,withVCmedium$len)
t.test(withVClarge$len,withVCmedium$len)$confidence
t.test(withVClarge$len,withVCmedium$len)$conf
?power.t.test
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="one.sample")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="one.sample", alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="two.sample", alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="paired", alternative="one.sided")
power.t.test(power=0.9,delta=0.01,sd=0.04, sig.level=0.05,type="paired", alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.10,type="paired", alternative="one.sided")
?p.adjust
44-42.04+c(-1,1)*12*qt(0.975,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.95,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.99,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.97,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.995,574)*sqrt(2/288)
library(manipulate)
library(UsingR)
library(usingR)
install.packages("UsingR")
library(UsingR)
data(galton)
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
?manipulate()
manipulate(myplot(beta), beta=slider(0.6,1.2))
?slider()
manipulate(myplot(beta), beta=slider(0.6,1.2,step=0.02))
detach("package:aplpack", unload=TRUE)
manipulate(myplot(beta), beta=manipulate.slider(0.6,1.2,step=0.02))
?lm()
lm((child-mean(child))~(parent-mean(parent)) -1, data=galton)
lm(I(child-mean(child))~I(parent-mean(parent)) -1, data=galton)
manipulate(myplot(beta), beta=manipulate::slider(0.6,1.2,step=0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), manipulate::beta = slider(0.6, 1.2, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = manipulate::slider(0.6, 1.2, step = 0.02))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x -1)
plot(x,y)
?plot
?lm
data(mtcars)
lm(mpg~weight, date=mtcars)
lm(mpg~weight, data=mtcars)
lm(mtcars$mpg ~ mtcars$weight)
lm(mtcars$mpg ~ mtcars$wt)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mu <-mean(x)
sd<-stdev(x)
stdev<-sd(x)
x<-(x-mu)/sd
x<-(x-mu)/stdev
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(y~x)
mean(x)
library(AppliedPredictiveModeling)
install(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library("AppliedPredictiveModeling", lib.loc="~/R/win-library/3.1")
install.packages("caret")
library("caret", lib.loc="~/R/win-library/3.1")
data(AlzheimerDisease)
adData<-dataframe(diagnosis, predictors)
adData<-data.frame(diagnosis, predictors)
?createDataPartition()
trainIndex=createDataPartition(diagnosis, p=0.5, list=FALSE)
trainIndex=createDataPartition(diagnosis, p=0.5)
training=adData[trainIndex,]
trainIndex=createDataPartition(diagnosis, p=0.5, list=FALSE)
training=adData[trainIndex,]
data(concrete)
set.seed(975)
inTrain=createDataPartition(concrete$CompressiveStrength,p=3/4)
inTrain=createDataPartition(concrete$CompressiveStrength,p=3/4)[[1]]
training=concrete[inTrain,]
testing=concrete[-inTrain,]
summary(concrete)
?cut2()
library("Hmisc", lib.loc="~/R/win-library/3.1")
?cut2()
training$Cement<-cut2(training$Cement,m=7)
training$BlastFurnacesSlag<-cut2(training$BlastFurnacesSlag,m=7)
training$FlyAsh<-cut2(training$FlyAsh,m=7)
training$Water<-cut2(training$Water,m=7)
training$SuperPlasticizer<-cut2(training$SuperPlasticizer,m=7)
training$Superplasticizer<-cut2(training$Superplasticizer,m=7)
training$BlastFurnaceSlag<-cut2(training$BlastFurnaceSlag,m=7)
training$CourseAggregate<-cut2(training$CourseAggregate,m=7)
training$CoarseAggregate<-cut2(training$CoarseAggregate,m=7)
training$FineAggregate<-cut2(training$FineAggregate,m=7)
training$Age<-cut2(training$Age,m=7)
training$Age<-cut2(training$Age,m=7)
training=concrete[inTrain,]
training$Age<-cut2(training$Age,g=7)
training$FineAggregate<-cut2(training$FineAggregate,g=7)
training$CoarseAggregate<-cut2(training$CoarseAggregate,g=7)
training$BlastFurnaceSlag<-cut2(training$BlastFurnaceSlag,g=7)
training$Superplasticizer<-cut2(training$Superplasticizer,g=7)
training$FlyAsh<-cut2(training$FlyAsh,g=7)
training$Water<-cut2(training$Water,g=7)
training$Cement<-cut2(training$Cement,g=7)
?qplot()
?plot()
plot(training$CompressiveStrength)
qplot(training$CompressiveStrength, colour=training$Cement)
plot(training$CompressiveStrength, col=training$Cement)
plot(training$CompressiveStrength, col=training$BlastFurnaceSlag)
plot(training$CompressiveStrength, col=training$FlyAsh)
plot(training$CompressiveStrength, col=training$Water)
plot(training$CompressiveStrength, col=training$Age)
plot(training$CompressiveStrength, col=training$SuperPlasticizer)
plot(training$CompressiveStrength, col=training$Superplasticizer)
plot(training$CompressiveStrength, col=training$CoarseAggregate)
plot(training$CompressiveStrength, col=training$FineAggregate)
training=cement[inTrain,]
training=concrete[inTrain,]
qplot(training$Superplasticizer)
inTrainAD<-createDataPartition(adData$diagnosis, p=3/4)[[1]]
trainingAD=adData[inTrainAD,]
testingAD=adData[-inTrainAD,]
?preProcess()
summary(trainingAD)
trainingAD[,IL*]
trainingAD[,[IL*]]
trainingAD[,age]
trainingAD[,[age]]
trainingAD[,["age"]
trainingAD[,"age"]
trainingAD[,"IL*"]
row.labels(trainingAD)
row.label(trainingAD)
?grep()
trainingAD[,grep("IL*",names(trainingAD))]
grep("IL*",names(trainingAD))
names(trainingAD)
grep("IL_",names(trainingAD))
grep("\\IL_",names(trainingAD))
grep("\\bIL_",names(trainingAD))
subTrainAD<-trainingAD[,grep("\\bIL_",names(trainingAD))]
preProcess(subTrainAD,thresh=0.8)
preProcess(subTrainAD,thresh=0.8, verbose=TRUE)
preProcess(subTrainAD,method="pca", thresh=0.8, verbose=TRUE)
preProcess(subTrainAD,method="pca", thresh=0.8)
newTrain<-data.frame[trainingAD$diagnosis,subTrainAD]
newTrain<-colbind(trainingAD$diagnosis,subTrainAD)
newTrain<-cbind(trainingAD$diagnosis,subTrainAD)
?glm()
names(newTrain)[names(newTrain=="trainingAD$diagnosis")]<-"diagnosis"
names(newTrain)[1]<-"diagnosis"
glm(diagnosis~.,data=newTrain)
newTrain$diagnosis
train(diagnosis ~ ., date=newTrain, method="glm")
train(diagnosis ~ ., data=newTrain, method="glm")
lm(diagnosis ~ ., data=newTrain)
glm(diagnosis ~ ., data=newTrain)
newTrain[diagnosis="Impaired",diagnosis]
newTrain[diagnosis=="Impaired","diagnosis"]
newTrain[newtrain$diagnosis=="Impaired","diagnosis"]
newtrain$diagnosis
newTrain$diagnosis
newTrain[newTrain$diagnosis=="Impaired","diagnosis"]
train(diagnosis ~ ., data=newTrain, method="glm")
install.packages("e1071")
library("e1071", lib.loc="~/R/win-library/3.1")
train(diagnosis ~ ., data=newTrain, method="glm")
modFit1<-train(diagnosis ~ ., data=newTrain, method="glm")
summary(modFit1$finalModel)
?predict()
predict(modFit1,newdata=testingAD)
?confusion matrix
pred1<-predict(modFit1,newdata=testingAD)
xtab1<-table(pred1,testingAD$diagnosis)
confusionMatrix(xtab1)
preProc<-preProcess(newTrain[,-1], method="pca", thresh=0.8)
trainPC<-predict(preProc,newTrain[,-1])
modFit2<-train(newTrain$diagnosis ~ ., data=trainPC, method="glm")
pred2<-predict(modFit2,newdata=testingAD)
testPC<-predict(preProc,testingAD[,-1])
subTestAD<-testingAD[,grep("\\bIL_",names(testingAD))]
newTest<-cbind(testingAD$diagnosis,subTestAD)
names(newTest)[1]<-"diagnosis"
testPC<-predict(preProc,newTest[,-1])
pred2<-predict(modFit2,newdata=testPC)
xtab2<-table(pred2,testingAD$diagnosis)
confusionMatrix(xtab2)
library("AppliedPredictiveModeling", lib.loc="~/R/win-library/3.1")
library("caret", lib.loc="~/R/win-library/3.1")
library("e1071", lib.loc="~/R/win-library/3.1")
set.seed(3433)
data(AlzheimerDisease)
adData=data.frame(diagnosis,predictors)
inTrain=createDataPartition(adDatadiagnosis,p=3/4)[[1]]
inTrain=createDataPartition(adData$diagnosis,p=3/4)[[1]]
training=adData[inTrain,]
testing=adData[-inTrain,]
subTestAD<-testing[,grep("\\bIL_",names(testing))]
subTrainAD<-training[,grep("\\bIL_",names(training))]
subTrainAD<-cbind(diagnosis,subTrainAD)
diagnosis
TrainAD<-cbind(diagnosis,subTrainAD)
trainDiagnosis<-diagnosis[inTrain]
testDiagnosis<-diagnosis[-inTrain]
TrainAD<-cbind(trainDiagnosis,subTrainAD)
testAD<-cbind(testDiagnosis,subTrainAD)
testAD<-cbind(testDiagnosis,subTestAD)
set.seed(3433)
data(AlzheimerDisease)
adData=data.frame(diagnosis,predictors)
adSubData<-adData[,grep("\\bIL_",names(adData))]
data(AlzheimerDisease)
set.seed(3433)
subPredictors<-predictors[,grep("\\bIL_",names(predictors))]
adData=data.frame(diagnosis,subPredictors)
inTrain=createDataPartition(adData$diagnosis,p=3/4)[[1]]
training=adData[inTrain,]
testing=adData[-inTrain,]
?train()
modFit1<-train(diagnosis ~ ., data=training, method="glm")
summary(modFit1$finalModel)
pred1<-predict(modFit1,newdata=testing)
xtab1<-table(pred1,testing$diagnosis)
confusionMatrix(xtab1)
summary(modFit1$finalModel)
preProc<-preProcess(training[,-1],method="pca",thresh=0.8)
?predict()
pred2<-predict(preProc,training[,-1],method="glm")
?train()
trainPC<-predict(preProc,training[,-1])
modelFit2<-train(training$diagnosis ~ .,method="glm",data=trainPC)
testPC<-predict(preProc,testing[,-1])
summary(modelFit2$finalModel)
confusionMatrix(testing$diagnosis,predict(modelFit2,testPC))
x<-c(.586, .166, -0.042, -0.614, 11.72)
y<-c(0.549, -0.026, -0.127, -0.751, 1.344)
?hat
hatvalues(y~x)
hatvalues(lm(y~x))
dfbetas(lm(y~x))
data(mtcars)
lm(mpg~factor(cyl)+wt, data=mtcars)
lm(mpg~factor(cyl), data=mtcars)
setwd("~/GitHub/LinRegress_Proj")
source('~/GitHub/LinRegress_Proj/WIP.R')
require(stats)
require(graphics)
?pairs
pairs(mtcars,panel=panel.smooth.main="mtCars")
pairs(mtcars,panel=panel.smooth,main="mtCars")
summary(lm(mpg~.,data=mtcars))
?cov
cov(mtcars)
cor(mtcars)
cor(mtcars,method="kendall")
model1<-lm(mpg~am, data=mtcars)
?update()
model2<-update(model1,mpg~am + wt)
model3<-update(model1,mpg~am + wt + cyl)
anova(model1, model2, model3)
?mtcars()
summary(model1)$coeff
summary(model2)$coeff
summary(model3)$coeff
model4<-update(model1,mpg~am + wt + cyl + hp)
model5<-update(model1,mpg~am + wt + cyl + hp + carb)
anova(model1, model2, model3, model4, model5)
summary(model4)$coeff
summary(model5)$coeff
?pairs()
pairs(mpg~.,data=mtcars)
pairs(.~mpg,data=mtcars)
pairs(mpg~.,data=mtcars,lower.panel=NULL)
pairs(mpg~cyl+disp+hp+drat+wt+vs+am,data=mtcars)
par(mfrow=c(3,3))
plot(mpg~cyl, data=mtcars)
plot(mpg~disp, data=mtcars)
plot(mpg~hp, data=mtcars)
plot(mpg~drat, data=mtcars)
plot(mpg~wt, data=mtcars)
plot(mpg~vs, data=mtcars)
plot(mpg~am, data=mtcars)
plot(mpg~gear, data=mtcars)
plot(mpg~carb, data=mtcars)
cor(mtcars)
